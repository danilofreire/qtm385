---
title: DATASCI 385 - Experimental Methods
subtitle: Lecture 22 - Survey Experiments for Sensitive Topics
author:
  - name: Danilo Freire
    email: danilo.freire@emory.edu
    affiliations: Department of Data and Decision Sciences <br> Emory University
format:
  clean-revealjs:
    self-contained: true
    code-overflow: wrap
    footer: "[Sensitive Topics](https://raw.githack.com/danilofreire/datasci385/main/lectures/lecture-22/22-survey2.html)"
transition: slide
transition-speed: default
scrollable: true
engine: knitr
revealjs-plugins:
  - multimodal
editor:
  render-on-save: true
---

# Hello, everyone! üòâ {background-color="#2d4563"}

# Notes about the group project {background-color="#2d4563"}

## Group project presentations

:::{style="font-size: 24px; margin-top: 30px;"}
- The simulated datasets have been sent to you by email
- [Please check if the data are complete and let me know if you have any issues]{.alert}
  - It's possible that I did not include some variables that you need. [Please let me know]{.alert} üòâ
- You will have [about 15 minutes]{.alert} to present your project, with [5 minutes for questions]{.alert}
- The order of the presentations has also been randomised:

:::{.columns}
:::{.column width="50%"}
- [Wednesday, December 03:]{.alert}
- Caffeine consumption and cognitive performance: Max, Sherelle, Ari, and William
- Causal Alignment Prompting: Mingke, Nicole, Anny, and Zixuan
- Effect of Monitoring on Perfomance: Lucy, Francisco, Gina, Bert, Tiger, and Toni
- Music and Vocabulary: Peter, Oscar, Sarah, and Vera
:::

:::{.column width="50%"}
- [Monday, December 08:]{.alert}
- Sleep and Stress: Rola, Sissi, Chrissy, and Selena
- AI and Assessment Scores: Tammy, Rami, Tiffany, Tashfia, and Aadit
- Framing Effects and Student Choices: Katie, Yoonsuh, Krishang, and Vidhant
:::
:::
:::

# Brief recap üìö {background-color="#2d4563"}

## Survey experiments
### Core components

:::{style="font-size: 26px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- [Survey experiments]{.alert} combine random assignment with survey methods to study attitudes
- Main applications: [behavioural economics]{.alert}, [psychology]{.alert}, [marketing]{.alert}, [political behaviour]{.alert}, and [public opinion]{.alert}
- Core design variations:
  - [Presence/absence]{.alert} of stimuli
  - [Dosage levels]{.alert} of treatment intensity
  - [Qualitative variations]{.alert} in treatment content
:::

:::{.column width="50%"}
- Validation methods:
  - [Manipulation checks]{.alert} post-treatment
  - [Placebo treatments]{.alert} for specificity testing
  - [Non-equivalent outcomes]{.alert} for effect containment
- Common implementations:
  - [Question wording]{.alert} manipulations
  - [Vignette designs]{.alert} with randomised attributes
  - [Audio or video]{.alert} stimuli
:::
:::
:::

# Today's plan üìÖ {background-color="#2d4563"}

## Survey experiments with a twist

:::{style="font-size: 26px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- What to do when [subjects have an incentive to lie?]{.alert}
- [Sensitive topics]{.alert} are often difficult to study
- [Social desirability bias]{.alert} is a common problem in survey research
- We need [special techniques]{.alert} to study these problems
- [List experiments]{.alert}, [randomised response technique]{.alert}, [endorsement experiments]{.alert}, and [conjoint experiments]{.alert} are possible solutions
- Maintains [plausible deniability]{.alert} for respondents
- Software to estimate these models: <http://sensitivequestions.org/>
:::

:::{.column width="50%"}
- [List experiments]{.alert} measure prevalence indirectly through item counts
- [Randomised response]{.alert} techniques use probability models for anonymity
- [Endorsement experiments]{.alert} assess support without direct attribution
- [Conjoint analysis]{.alert} measures preferences through trade-off scenarios
- Sometimes requires careful [probability weighting]{.alert} in analysis
:::
:::
:::

# List experiments üìã {background-color="#2d4563"}

## What is a list experiment?

:::{style="font-size: 23px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- The logic of list experiments is simple
- Respondents are presented with [a list of items and asked how many they agree with]{.alert}
  - Just [how many]{.alert} items, not which ones
- The list includes a [sensitive item]{.alert} (e.g., "I have committed a crime") and several non-sensitive items
- The [sensitive item is randomly assigned]{.alert} to a subset of respondents
- The key is to compare the average number of items agreed with between the treatment group (who sees the sensitive item) and the control group (who does not)
- The difference in means provides an estimate of the prevalence of the sensitive item
- This method is also known as the [item count technique]{.alert}
:::

:::{.column width="50%"}
:::{style="text-align: center;"}
![](figures/imai.png){width=100%}

Source: [Blair and Imai (2012)](https://imai.fas.harvard.edu/research/files/listP.pdf)
:::
:::
:::
:::

## Example 
### Measuring prejudice

:::{style="font-size: 32px; margin-top: 30px; "}

> Now I‚Äôm going to read you three things that sometimes make people
angry or upset. After I read all three, just tell me HOW MANY of
them upset you. (I don‚Äôt want to know which ones, just how many.)
>
> (1) the federal government increasing the tax on gasoline
> (2) professional athletes getting million-dollar-plus salaries
> (3) large corporations polluting the environment
>
> How many, if any, of these things upset you?
:::

## Example of a list experiment
### Measuring prejudice

:::{style="font-size: 32px; margin-top: 30px;"}

> Now I‚Äôm going to read you four things that sometimes make people
angry or upset. After I read all four, just tell me HOW MANY of
them upset you. (I don‚Äôt want to know which ones, just how many.)
>
> (1) the federal government increasing the tax on gasoline
> (2) professional athletes getting million-dollar-plus salaries
> (3) large corporations polluting the environment
> (4) **a black family moving next door to you**
>
> How many, if any, of these things upset you?
:::

## Some notation 

:::{style="font-size: 27px; margin-top: 30px;"}
- Sample of respondents $N$, where $T_i = 1$ if respondent $i$ is in the treatment group and $T_i = 0$ if in the control group
- $J$ is the number of items in the control list, $J + 1$ is the number of items in the treatment list
- $Z_{ij}(t)$ a binary variable denoting respondent $i$'s preference for the $j$th control item for $j = 1, \dots , J$ under the treatment status $t = 0, 1$
- $Y_{i}(0) = \sum_{j=1}^{J} Z_{ij}(0)$ is the potential answer $i$ would give if asked about the control list
- $Y_{i}(1) = \sum_{j=1}^{J+1} Z_{ij}(1)$ is the number of items in the treatment list that respondent $i$ agrees with
- The observed response is $Y_i = Y_i(T_i)$, where $Y_i(0)$ is in the range of $\{0,1, \dots, J\}$ and $Y_i(1)$ is in the range of $\{0,1, \dots J + 1\}$
- Now let's discuss the assumptions...
:::

## Assumptions

:::{style="font-size: 21px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
### No design effects

- First, we need to assume that the [addition of the sensitive item does not change the sum of affirmative answers to the control items]{.alert}
- It is [not necessary]{.alert} that respondents answer the control items truthfully, but the average number of affirmative answers must be the same in both groups
- This is the [no design effects]{.alert} assumption
- Formally, for each respondent $i = 1, \dots, N$, we assume:

$$
\sum_{j=1}^{J} Z_{ij}(0) = \sum_{j=1}^{J} Z_{ij}(1)
$$
:::

:::{.column width="50%"}
### No liars

- Second, we need to assume that the [sensitive item is not a lie]{.alert}
- That is, [all respondents give truthful answers for the sensitive item]{.alert}
- This is a [strong assumption]{.alert}, as you can imagine

$$
Z_{i,J+1}(1) = Z^*_{i,J+1} 
$$

where $Z^*_{i,J+1}$ represents a truthful answer to the sensitive item. The treatment effect is

$$\hat{\tau} = \frac{1}{N_1} \sum_{i=1}^{N} T_i Y_i - \frac{1}{N_0} \sum_{i=1}^{N} (1 - T_i) Y_i,$$

where $N_1 = \sum_{i=1}^{N} T_i$ is the size of the treatment group and $N_0 = N - N_1$ is the size of the control group
:::
:::
:::

## More about list experiments
### Notes about the design

:::{style="font-size: 21px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- List experiments have several advantages, as they are [easy to implement]{.alert} and [clear to respondents]{.alert}
- But they have some issues as well:
  - [Limited power]{.alert} to detect small effects
  - [Floor effects]{.alert}: If many respondents [disagree with all or most items]{.alert}, it is hard to estimate the prevalence of the sensitive item
  - [Ceiling effects]{.alert}: If someone agrees with all items, [we know for sure they agree with the sensitive item]{.alert}
  - [Sample homogeneity]{.alert}: If the sample is too homogeneous, it may be hard to detect differences
:::

:::{.column width="50%"}
- But there are some solutions for these problems
- [Use items that contradict each other]{.alert} to reduce ceiling and floor effects
  - Example: ask about [pro-gun]{.alert} and [pro-choice]{.alert} items 
- A [weakly informative Bayesian prior]{.alert} and [covariates]{.alert} can also be used to reduce ceiling and floor effects
- You can also add [direct questions]{.alert} to the experiment and use a [weighted average of the direct question estimate and the list experiment estimate among those who answer ‚ÄúNo‚Äù to the direct question]{.alert} ([Arrow et al. 2015](https://doi.org/10.1093/jssam/smu023))
- You can also include [multiple sensitive items]{.alert} in the list experiment
- The main issue is to [interpret the results]{.alert} correctly, so we usually see [what explains one sensitive item]{.alert} in the list experiment
:::
:::
:::
i
## Example of a list experiment
### Measuring prejudice

:::{style="font-size: 32px; margin-top: 30px;"}
- Let's revisit the previous example:

> Now I‚Äôm going to read you four things that sometimes make people
angry or upset. After I read all four, just tell me HOW MANY of
them upset you. (I don‚Äôt want to know which ones, just how many.)
>
> (1) the federal government increasing the tax on gasoline
> (2) professional athletes getting million-dollar-plus salaries
> (3) large corporations polluting the environment
> (4) **a black family moving next door to you**
>
> How many, if any, of these things upset you?
:::

## R example

:::{style="font-size: 24px; margin-top: 30px;"}

- More information at <https://list.sensitivequestions.org/articles/getting-started.html>

```{r}
#| echo: true
#| eval: true
library(list)
data(race)

lm.results <- ictreg(y ~ 1, data = race, treat = "treat", J=3, method = "lm")
summary(lm.results)
```
:::

## R example

:::{style="font-size: 24px; margin-top: 30px;"}

- More information at <https://list.sensitivequestions.org/articles/getting-started.html>

```{r}
#| echo: true
#| eval: true
library(list)
data(race)

lm.results <- ictreg(y ~ south + age + male + college, data = race, 
                  treat = "treat", J=3, method = "lm")
summary(lm.results)
```
:::

# Did hidden Trump voters exist? {background-color="#2d4563"}

## Did hidden Trump voters exist?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
:::{.columns}
:::{.column width="50%"}
![](figures/trump-abstract.png){width=100%}
:::

:::{.column width="50%"}
:::{style="margin-top: 50px;"}
![](figures/trump-list.png){width=100%}
:::
:::
:::

Source: [Coppock (2017)](https://alexandercoppock.com/coppock_2017a.pdf)
:::

## Did hidden Trump voters exist?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/trump-results.png){width=100%}
:::

# Do Russians support the war in Ukraine? {background-color="#2d4563"}

## Do Russians support the war in Ukraine?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/russia-list.png){width=100%}

Source: [Chapovski (2022)](https://journals.sagepub.com/doi/full/10.1177/20531680221108328)
:::

## Do Russians support the war in Ukraine?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/russia-results01.png){width=100%}
:::

## Do Russians support the war in Ukraine?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/russia-results.png){width=100%}
:::

# Endorsement experiments {background-color="#2d4563"}

## What is an endorsement experiment?

:::{style="font-size: 25px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- Endorsement experiments are a type of survey experiment that measure [support for a policy or candidate]{.alert}
- They are a variation of the [vignette experiment]{.alert}, where respondents are presented with a scenario and asked to evaluate it
- Here, the scenario includes an endorsement from a [prominent figure]{.alert} or [group]{.alert}
- These experiments are often used to study [partisan bias]{.alert}, [group identity]{.alert}, or [framing effects]{.alert}
- The main advantage of endorsement experiments is that they can [elicit preferences]{.alert} without directly asking about them
:::

:::{.column width="50%"}
- While it is easy to estimate them when there is [one group involved]{.alert}, it is more difficult when there are [multiple groups]{.alert}
- It is a little hard to combine the items, but it is possible
- A solution is to use [Bayesian hierarchical models]{.alert}, which is described in this (very technical) paper: [Bullock et al (2011)](https://imai.fas.harvard.edu/research/files/support.pdf)
- We can also use conjoint experiments, as we'll see in a bit!
:::
:::
:::

## Example
### Measuring Support for Militant Groups in Pakistan

:::{style="font-size: 21px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- Militant violence in Pakistan is a serious international problem, yet little is known about who supports militant organisations and why
- There is a strong incentive for locals to [falsify information to avoid repercussions]{.alert}
- Also, [asking respondents directly poses safety risks]{.alert} for researchers and participants alike 
- Unlike a direct measure, non-response and social desirability biases are minimised since [respondents are reacting to the policy and not directly to the group itself]{.alert} (or so it seems! üòÖ)
- The authors asked respondents about their level of support for polio vaccinations, curriculum reforms, crime regulations, and border disputes
:::

:::{.column width="50%"}
- Control group:

```{verbatim}
The World Health Organization recently announced 
a plan to introduce universal polio vaccination 
across Pakistan. How much do you support
such a plan?
(1) A great deal; (2) A lot; (3) A moderate amount; 
(4) A little; (5) Not at all.
```

- Treatment group:

```{verbatim}
The World Health Organization recently announced 
a plan to introduce universal polio vaccination 
across Pakistan. **Pakistani militant groups 
fighting in Kashmir have voiced support for 
this program.** How much do you support such a plan?
(1) A great deal; (2) A lot; (3) A moderate amount; 
(4) A little; (5) Not at all.
```
:::
:::
:::

## Results

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/endorsement-results.png){width=100%}
:::

# Did political endorsement influence mass opinion during COVID-19? {background-color="#2d4563"}

## Did political endorsement influence mass opinion during COVID-19?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
:::{.columns}
:::{.column width="50%"}
![](figures/covid-abstract.png){width=100%}
:::

:::{.column width="50%"}
![](figures/covid-experiment.png){width=100%}
:::
:::

Source: [Gadarian et al (2021)](https://doi.org/10.1080/17457289.2021.1924727)
:::

## Did political endorsement influence mass opinion during COVID-19?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/covid-results01.png){width=100%}
:::

## Did political endorsement influence mass opinion during COVID-19?

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/covid-results02.png){width=100%}
:::

# Randomised response techniques üé≤ {background-color="#2d4563"}

## Randomised response

:::{style="font-size: 23px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- This is an old technique (Werner 1965, Boruch 1971) that is used to [reduce social desirability bias]{.alert}
- The main idea is the following:
  - The respondent rolls a die or other randomising device out of view of the enumerator
  - The enumerator does not know the outcome of the randomisation
  - For instance, if a 1 shows on the die, the respondent says no
  - If a 6 shows, the respondent says yes
  - If any other number shows, the respondent answers truthfully
  - The enumerator sees the answer, but does not know if it is true or random
:::

:::{.column width="50%"}
- The method works because [the probabilities are known]{.alert} so we can estimate the true proportion of respondents who agree with the sensitive item
- However, the method is [a little confusing to respondents]{.alert} and it is important to either [run the experiment in person]{.alert} or [provide clear instructions]{.alert} if running it online
- Believe it or not, this is [the most effective]{.alert} method to reduce social desirability bias!
:::
:::
:::

## Xenophobia and antisemitism in Germany

:::{style="font-size: 23px; margin-top: 30px; text-align: center;"}
:::{.columns}
:::{.column width="50%"}
![](figures/germany-abstract.png){width=100%}
:::

:::{.column width="50%"}
![](figures/germany-experiment.png){width=100%}
:::
:::

Source: [Krumpal (2012)](https://www.sciencedirect.com/science/article/abs/pii/S0049089X12001172)
:::

## Xenophobia and antisemitism in Germany

:::{style="font-size: 24px; margin-top: 30px; text-align: center;"}
![](figures/germany-results.png){width=100%}
:::

# Conjoint analysis {background-color="#2d4563"}

## Conjoint experiments

:::{style="font-size: 23px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- Conjoint analysis measures preferences for [multiple attributes]{.alert} of a product, service, or policy
- The method aims to understand how different factors influence decision-making
- It is also used to study [trade-offs]{.alert} between different attributes
- As with the other experiments we discussed, conjoint analysis [provides plausible deniability]{.alert} for respondents
- Why is that? Because [respondents are not asked about their preferences directly]{.alert}
- Instead, they are presented with a series of hypothetical scenarios and asked to choose their preferred option
:::

:::{.column width="50%"}
- The main advantage of conjoint analysis is that it allows researchers to [study complex preferences]{.alert} in a more realistic way
- Another advantage is that the method is very robust, flexible, and adaptable to various research contexts
- It also [increases sample size significantly]{.alert} as respondents are presented with several scenarios
- However, it can be [time-consuming]{.alert} to design and analyse, but that's pretty much the only con üòâ
- Ah, software to implement it is [quite difficult to use as well!]{.alert}
- See [my own experiment](https://github.com/danilofreire/lynching-experiment-brazil) for an example (we will discuss it in the next lecture!)
:::
:::
:::

## Hainmueller et al (2014)

:::{style="font-size: 23px; margin-top: 30px; text-align: center;"}
:::{.columns}
:::{.column width="40%"}
- Assumptions:
  - No carryover effects
  - No profile-order effects
  - Randomisation of profiles
  - Need to cluster errors because answers are not independent (a single individual chooses many profiles)

- [Survey design tool](https://github.com/astrezhnev/conjointsdt)
- [`cregg` R package](https://github.com/leeper/cregg)
:::

:::{.column width="60%"}
:::{style="text-align: center;"}
![](figures/hainmueller-abstract.png){width=100%}
:::
:::

Source [Hainmueller et al (2014)](https://www.researchgate.net/profile/Jens-Hainmueller/publication/256051925_Causal_Inference_in_Conjoint_Analysis_Understanding_Multidimensional_Choices_Via_Stated_Preference_Experiments/links/59c2f834aca272295a0df9fd/Causal-Inference-in-Conjoint-Analysis-Understanding-Multidimensional-Choices-Via-Stated-Preference-Experiments.pdf?_sg%5B0%5D=started_experiment_milestone&origin=journalDetail)
:::
:::

## Example: Immigration applicants (US)

:::{style="font-size: 23px; margin-top: 30px; text-align: center;"}
![](figures/hainmueller-experiment.png){width=100%}
:::

## Example: Immigration applicants (US)

:::{style="font-size: 23px; margin-top: 30px; text-align: center;"}
![](figures/hainmueller-results.png){width=100%}
:::

## Example: Presidential candidates (US)

:::{style="font-size: 23px; margin-top: 30px; text-align: center;"}
![](figures/hainmueller-results02.png){width=100%}
:::

# Conclusion {background-color="#2d4563"}

## Conclusion

:::{style="font-size: 23px; margin-top: 30px;"}
:::{.columns}
:::{.column width="50%"}
- [How cool are these methods?!]{.alert} ü§ì
- There are many other methods to study sensitive topics
- Today we saw four of them: 
  - [List experiments]{.alert}
  - [Endorsement experiments]{.alert}
  - [Randomised response techniques]{.alert}
  - [Conjoint analysis]{.alert}
- Please remember that these methods are not perfect, and that they have several assumptions
- They are also areas of [active research]{.alert}, so please be mindful that something new may come up üòâ
:::

:::{.column width="50%"}
- If you are interested in learning more about these methods, please check the following `R` packages:
- [`list`](https://cran.r-project.org/web/packages/list/index.html)
- [`endorse`](https://cran.r-project.org/web/packages/endorse/index.html)
- [`rr`](https://cran.r-project.org/web/packages/rr/index.html)
- [`cregg`](https://github.com/leeper/cregg)
- Visit the website <http://sensitivequestions.org/> for more information
- And let me know if you'd like to learn more about this topic! ü§ì
:::
:::
:::

# ...And that's all for today! üéâ {background-color="#2d4563"}

# Thank you for your attention! üôè {background-color="#2d4563"}