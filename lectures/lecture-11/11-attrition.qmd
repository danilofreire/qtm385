---
title: DATASCI 385 - Experimental Methods
subtitle: Lecture 11 - Attrition
author:
  - name: Danilo Freire
    email: danilo.freire@emory.edu
    affiliations: Department of Data and Decision Sciences <br> Emory University
format:
  clean-revealjs:
    self-contained: true
    code-overflow: wrap
    footer: "[Attrition](https://raw.githack.com/danilofreire/datasci385/main/lectures/lecture-11/11-attrition.html)"
transition: slide
transition-speed: default
scrollable: true
engine: knitr
revealjs-plugins:
  - multimodal
editor:
  render-on-save: true
---

# Hello, everyone! <br> How are you doing today? üòâ {background-color="#2d4563"}

# Brief recap üìö {background-color="#2d4563"}

## Last class

:::{style="margin-top: 30px; font-size: 28px;"}
- [Two-sided non-compliance]{.alert} occurs when both treatment and control groups experience imperfect compliance
- Four compliance types:
  - [Compliers]{.alert}: Follow treatment assignment
  - [Never-takers]{.alert}: Never receive treatment
  - [Always-takers]{.alert}: Always seek treatment
  - [Defiers]{.alert}: Do opposite of assignment (rare)
- [Monotonicity assumption]{.alert} required (no defiers) for identification
- [IV methods]{.alert} estimate CACE: $\tau_{LATE} = \frac{ITT_Y}{ITT_D}$
:::

# Today's plan üìã {background-color="#2d4563"}

## Attrition in experiments
### Another missing data problem

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- [Attrition]{.alert}: Loss of participants before study completion
- Two main types:
  - [Random attrition]{.alert}: Missingness unrelated to treatment/outcome
  - [Non-random/Systematic attrition]{.alert}: Missingness correlates with variables
- Impacts:
  - Reduced [statistical power]{.alert} üìâ
  - Potential [selection bias]{.alert} threat to validity
  - Compromised [generalisability]{.alert} üåê
:::

:::{.column width=50%}
:::{style="text-align: center; margin-top: -30px;"}
![](figures/drake.png){width=100%}
:::
:::
:::
:::

## Handling Attrition

:::{style="margin-top: 30px; font-size: 29px;"}
- Analysis methods:
  - [Inverse probability weighting]{.alert} (IPW)
  - [Extreme bounds analysis]{.alert} (EBA)
  - [Lee bounds]{.alert} (trimming the bounds)
- [IPW]{.alert} estimates ATE when missingness is related to observed variables
- [EBA]{.alert} is a robustness check that evaluates the sensitivity of the ATE to different assumptions about the missing data
- [Lee bounds]{.alert} are a way to trim the bounds to make them more informative
:::

# Attrition in Experiments üß© {background-color="#2d4563"}

## Attrition in experiments
### Missing outcome data

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- [Attrition]{.alert} is, unfortunately, another common issue in experiments
- When attrition is correlated with treatment, [it can bias estimates]{.alert}
- Several factors can lead to attrition:
  - [Non-compliance]{.alert}: Intervention too burdensome, unfair, or ineffective
  - [Survey fatigue]{.alert}: Participants lose interest over time
  - [Unforeseen events]{.alert}: Health issues, job changes, etc.
  - [Data collection errors]{.alert}: Intentional or not
:::

:::{.column width=50%}
- Attrition [forces scholars to make assumptions]{.alert} about missing data
- The main one being that [missingness is ignorable]{.alert}, that is, not related to the outcome
- Another approach is to assume that [missingness is related to observed variables]{.alert}
- In this case, [some statistical methods]{.alert} can be used to model the missingness mechanism
- Finally, we can [try to collect more data]{.alert} to reduce attrition, but this is not always feasible
:::
:::
:::

## Motivating example: RAND Health Insurance Experiment
### Does healthcare insurance improve health outcomes?

:::{style="margin-top: 30px; font-size: 25px;"}
- [RAND Health Insurance Experiment]{.alert} (HIE) was a large-scale study in the 1970s that randomly assigned families to different insurance plans
- The goal was to assess the impact of insurance on health outcomes
- The experiment covered 5%, 50%, 75%, or 100% of each family‚Äôs health costs, with the remaining covered by the family
- To insure families in the first three experimental groups against catastrophic financial loss, costs over $1,000 were covered by the experimental insurance plan
- The study found that insurance coverage [did not significantly affect health outcomes]{.alert}
- The conclusion was that [public health insurance]{.alert} was not cost-effective, thus the government did not need to expand it
- Overall, the study cost about $550 million in today‚Äôs dollars üòÆ
- However, the study had [high attrition]{.alert} rates, which may have biased the results!
:::

## Health expenditure and health outcomes in the RAND HIE

:::{style="margin-top: 30px; text-align: center; font-size: 20px;"}
![](figures/rand-hie.png){width=70%}

Column (1) shows the average for the group assigned catastrophic coverage. Columns (2)‚Äì(5) compare averages in the deductible, cost-sharing, free care, and any insurance groups with the average in column (1).

Source: Angrist and Pischke (2014, 19)
:::

## Attrition in RAND HIE

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- Statistical analyses found that [researchers excluded people who dropped out]{.alert}
- Initial refusal rates differed significantly:
    -  [8% of those assigned to the free care group refused]{.alert} to enrol after the baseline survey
    - [25% of those assigned to cost-sharing plans refused]{.alert} to enrol after the baseline survey
- Among those who enrolled, further attrition occurred during the 3- to 5-year study
:::

:::{.column width=50%}
- Withdrawal was [more common in experimental groups where subjects had to pay]{.alert} for health services
- Voluntary attrition rates varied by plan:
    - [0.4%]{.alert} in the free plan group
    - [6.7%]{.alert} in the cost-sharing plan groups
- Subjects in cost-sharing conditions who anticipated serious health problems might have dropped out to maintain existing coverage
- [What issues do you see with this attrition pattern?]{.alert}
:::
:::
:::

# Some notation üìù {background-color="#2d4563"}

## Attrition in experiments
### Using the potential outcomes framework

:::{style="margin-top: 30px; font-size: 27px;"}
- You're all familiar with the potential outcomes framework by now ü§ì
- Remember our variables from last class?
  - $Y_i(0)$ and $Y_i(1)$: Potential outcomes for individual $i$
  - $z_i$: Treatment assignment
  - $d_i$: Actual treatment received by individual $i$
  - $Y_i$: Observed outcome for individual $i$
- Here, let's first assume that there is [full compliance]{.alert} with treatment assignment, that is, $d_i = z_i$
- So far, so good? üòä
- Now, let's introduce [attrition]{.alert} to the mix and use a similar notation
:::

## Attrition in experiments
### Some new notation

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width=50%}
- Let $r_i$ (for [reported]{.alert}) be an indicator for whether individual $i$ remains in the study
- $r_i(z)$: This is a [new potential outcome related to attrition]{.alert}
- It represents whether [the outcome for person $i$ is reported]{.alert} (i.e., they stay in the study and we get their data) if they were assigned to treatment $z$
- $r_i(1)$: Whether the [outcome for person $i$ would be reported if they were in the treatment group]{.alert} 
  - $r_i(1) = 1$: Outcome is reported (person stays in the study) 
  - $r_i(1) = 0$: Outcome is missing (person drops out)
:::

:::{.column width=50%}
- Similarly, $r_i(0)$: Whether the [outcome for person $i$ would be reported if they were in the control group]{.alert}
  - $r_i(0) = 1$: Outcome is reported (person stays in the study)
  - $r_i(0) = 0$: Outcome is missing (person drops out)

$$r_i = r_i(0)(1 - z_i) + r_i(1)z_i $$

- If they are in the control group, their reporting outcome is just $r_i(0)$, and if they are in the treatment group, it is $r_i(1)$
- [Attrition occurs when some values are $r_i = 0$]{.alert}
- A bit formal, but just stating the obvious üòÖ
:::
:::
:::

## Four (latent) types of respondents

:::{style="margin-top: 30px; font-size: 28px;"}
- We can classify individuals into four types based on their response behaviour [(Lee 2009)](https://academic.oup.com/restud/article/76/3/1071/1590707):

  - [Always-reporters:]{.alert} $r_i(0) = 1$ and $r_i(1) = 1$ ‚Äî they always report their outcomes regardless of treatment assignment
  - [Never-reporters:]{.alert} $r_i(0) = 0$ and $r_i(1) = 0$ ‚Äî regardless of treatment status, they always attrite on the outcome
  - [If-treated reporters:]{.alert} $r_i(0) = 0$ and $r_i(1) = 1$ ‚Äî they report their outcomes only if assigned to treatment
  - [If-untreated reporters:]{.alert} $r_i(0) = 1$ and $r_i(1) = 0$ ‚Äî they report their outcomes only if assigned to control

- While this new framework is helpful, it has the same issue we discussed in our previous class: [we cannot know whether individuals are one type or another]{.alert} (more on this later!)
::: 



## When does bias occur?

:::{style="margin-top: 30px; font-size: 29px;"}
- Bias arises if the [characteristics of those who stay in the study]{.alert} $(r_i(z) = 1)$ [are systematically different from those who drop out]{.alert} $(r_i(z) = 0)$, and if these differences are [related to the potential outcomes]{.alert} $Y_i(z)$
- In other words, if [attrition is non-random]{.alert}, we have a problem!
- The [difference-in-means estimator does not recover the ATE for the entire subject pool, and it will not recover the ATE for any meaningful subgroup either!]{.alert}
- Why? 
  - Attrition might be [non-random within each of these baseline subgroups]{.alert}
  - For example, maybe younger people in the treatment group drop out more than older people, but the opposite can be true in the control group!
:::

# Special cases of attrition {background-color="#2d4563"}

## Special cases of attrition
### Missing independent of potential outcomes

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- [Random attrition]{.alert} is the best-case scenario!
- This claim is usually [not verified directly]{.alert}, but rather assumed
- Formally, 

$$Y_i(z) \perp R_i(z)$$

- In some cases this may be true, such as a computer malfunction that causes data loss to some participants
- We can actually test that using regression or randomisation inference!
  - Just regress $r_i$ on the covariates and treatment assignment and you should find no significant relationship
:::

:::{.column width=50%}
- If attrition is random, we can [ignore it]{.alert} and proceed with our analysis
- It still has issues, though:
  - [Reduced power]{.alert} due to smaller sample size
  - [Generalisability]{.alert} issues
- But at least we can [estimate the ATE]{.alert} without bias üòÖ
- [What are some other examples of random attrition?]{.alert} Can you think of any?
:::
:::
:::

## Special cases of attrition
### Missing related to observed variables

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- Since random attrition is rare, we often have to deal with [non-random attrition]{.alert}
- A special type if [missing independent of potential outcomes given X]{.alert}, or $MIPO | X$
- It is formally defined as:

$$Y_i(z) \perp R_i(z) | X_i$$

- You can include more covariates in $X_i$ if you think they are related to attrition
:::

:::{.column width=50%}
- Suppose that students with poor attendance are both more likely to be missing on the day of the assessment and
more likely to benefit from the intervention
- $MIPO|X$ means that if one [partitions the experimental sample by prior attendance, missingness is random within each subgroup]{.alert}
- Among students whose record of attendance is poor, there is no relationship between missing school on the day of the assessment and the subjects' potential outcomes
- The same goes for students with a good record of attendance
:::
:::
:::

# Inverse probability weighting {background-color="#2d4563"}

## Inverse probability weighting
### A way to handle missing related to observed variables

:::{style="margin-top: 30px; font-size: 26px;"}
- We can compensate for missing data by [weighting the observed data]{.alert}
- The idea is to [upweight the observations that are similar to the missing ones]{.alert}
- Let me give you a simple example:
  - Suppose we have 40 people in our experiment
  - 30 are men and 10 are women
  - The overall average would be $\frac{30}{40} \times$ men's average + $\frac{10}{40} \times$ women's average
- Now assume that 15 out of the 30 men drop out
- "Controlling for gender" (i.e., weighting):
  - The remaining 15 men produce an unbiased estimate of the average amongst 30 men
  - So we can just [count them twice]{.alert}!
  - This is the essence of [inverse probability weighting]{.alert} (IPW)
:::

## Inverse probability weighting
### The formula

:::{style="margin-top: 30px; font-size: 24px;"}
- IPW estimates ATE when $MIPO|X$ holds
- To estimate ATE, we need $E[Y_i(1)]$ and $E[Y_i(0)]$ (as you know!)
- When $MIPO|X$ holds, $E[Y_i(1)]$ is weighted average:

$$E[Y_i(1)] = \frac{1}{N} \sum_{i=1}^{N} \frac{Y_i(1) r_i(1)}{\pi_i(z = 1, x)},$$

  - $\pi_i(z = 1, x)$: share of non-missing subjects among treated with covariate profile $x$
  - Missing outcomes have no effect on sum
  - Reported outcomes weighted by $1/\pi_i(z = 1, x)$
  - Weights replace missing values with copies of non-missing values
- It's called inverse probability weighting because [observations are weighted by inverse probability of being observed]{.alert}
:::

## Motivating example for IPW

:::{style="margin-top: 30px; font-size: 26px;"}
- Treatment: [Educational programme at a community centre]{.alert}
- $X_i$: Covariate indicating proximity to the centre
    - $X_i = 1$: Lives near the community centre
    - $X_i = 0$: Lives far away
- Follow-up evaluation at the community centre
- [Attrition is related to $X_i$]{.alert}: People living far are less likely to show up
- [Potential outcomes differ by $X_i$]{.alert}: People living far away have higher potential outcomes
- Let's see how it can recover ATE when $MIPO|X$ holds!
:::

## Motivating example for IPW
### Potential outcomes and covariates

:::{style="margin-top: 30px; font-size: 24px;"}

| Observation | $Y_i(0)$ | $Y_i(1)$ | $r_i(0)$ | $r_i(1)$ | $Y_i(0) \vert r_i(0)$ | $Y_i(1) \vert r_i(1)$ | $X_i$ |
|-------------|----------|----------|----------|----------|-----------------------|-----------------------|-------|
| 1           | 3        | 4        | 1        | 1        | 3                     | 4                     | 1     |
| 2           | 4        | 7        | 1        | 1        | 4                     | 7                     | 1     |
| 3           | 3        | 4        | 1        | 1        | 3                     | 4                     | 1     |
| 4           | 4        | 7        | 1        | 1        | 4                     | 7                     | 1     |
| 5           | 10       | 14       | 0        | 0        | Missing               | Missing               | 0     |
| 6           | 12       | 18       | 0        | 0        | Missing               | Missing               | 0     |
| 7           | 10       | 14       | 1        | 1        | 10                    | 14                    | 0     |
| 8           | 12       | 18       | 1        | 1        | 12                    | 18                    | 0     |


:::

## Motivating example for IPW
### Calculation of ATE

:::{style="margin-top: 30px; font-size: 22px;"}
- ATE with complete data: $E[Y_i(1)] - E[Y_i(0)] = 3.5$
- Relevant proportions of non-missingness:
    - $\pi_i(z = 1, x = 1) = 1$
    - $\pi_i(z = 1, x = 0) = 1$
    - $\pi_i(z = 0, x = 1) = 1$
    - $\pi_i(z = 0, x = 0) = 0.5$
- Applying the weighted average formula:

$$E[Y_i(1)] = (\frac{1}{8}) (\frac{4}{1} + \frac{7}{1} + \frac{4}{1} + \frac{7}{1} + \frac{14}{0.5} + \frac{18}{0.5}) = 10.75,$$

$$E[Y_i(0)] = (\frac{1}{8}) (\frac{3}{1} + \frac{4}{1} + \frac{3}{1} + \frac{4}{1} + \frac{10}{0.5} + \frac{12}{0.5}) = 7.25,$$

$$E[Y_i(1)] - E[Y_i(0)] = 3.5.$$

- [IPW recovers the true ATE!]{.alert} üéâ
:::

## Downsides of IPW 
### When $MIPO|X$ is incorrect

:::{style="margin-top: 30px; font-size: 26px;"}
- [Incorrect $MIPO|X$ assumption]{.alert} leads to misleading estimates
- IPW gives [largest weights to high-attrition subgroups]{.alert}
- Biased subgroup estimate can disproportionately influence overall ATE
- IPW average may be [more biased than unweighted data]{.alert}
- Re-weighting [increases sampling variability]{.alert}
    - Extra weight on subsamples with many missing observations
- $MIPO|X$ discussion: [hypothetical scenarios]{.alert} with known potential outcomes
- In practice, researchers must [make assumptions about attrition]{.alert}
- Evaluating $MIPO|X$: [detective work and speculation]{.alert} üïµÔ∏è‚Äç‚ôÇÔ∏è
:::

# ATE Bounds {background-color="#2d4563"}

## Extreme bounds analysis
### A robustness check for attrition

:::{style="margin-top: 30px; font-size: 27px;"}
- Now, let's analyse the worst case scenario: when attrition is so severe that it [invalidates the $MIPO|X$ assumption]{.alert}
- In this case, there is no clear way to recover the ATE
- But we can do something about it!
- [Extreme bounds analysis]{.alert} (EBA - Manski bounds) is a robustness check that evaluates the [sensitivity of the ATE to different assumptions]{.alert}
- The idea is to [bound the ATE by the most extreme assumptions]{.alert} about the missing data
  - That is, we assume the [best and worst-case scenarios]{.alert} for the missing data
- [Sensitivity methods](https://scholar.google.com.br/scholar?hl=en&as_sdt=0%2C6&q=sensitivity+methods+causal+inference&btnG=) are a growing area of research in causal inference, and EBA is one of the most popular methods
:::

## Extreme bounds analysis
### The procedure

:::{style="margin-top: 30px; font-size: 27px;"}
-  Imagine the [missing outcomes from those who dropped out]{.alert}
-  We don't know what those outcomes are, but we can consider [two extreme scenarios]{.alert}:
  - [Best-case scenario]{.alert}: Assume the [dropouts in the treatment group would have had the best possible outcomes]{.alert}, and [dropouts in the control group would have had the worst possible outcomes]{.alert} (relative to the observed data) 
  - [Worst-case scenario]{.alert}: Assume the [dropouts in the treatment group would have had the worst possible outcomes]{.alert}, and [dropouts in the control group would have had the best possible outcomes]{.alert} 

- By calculating the ATE under these extreme assumptions, we get a range (upper bound and lower bound) that (hopefully üòÖ) contains the true ATE
:::

## A simple example

:::{style="margin-top: 30px; font-size: 27px;"}
:::{.columns}
:::{.column width=50%}
- Suppose our programme has the following outcomes if there is no attrition:
  - Average for the treatment group: $\frac{(7 + 10 + 6 + 6)}{4} = \frac{29}{4} = 7.25$
  - Average for the control group: $\frac{(3 + 7 + 5 + 6)}{4} = \frac{21}{4} = 5.25$
  - ATE: $7.25 - 5.25 = 2$
:::

:::{.column width=50%}
- Now, suppose that we only observe the following outcomes:
  - Average for the treatment group: $\frac{(7 + 10 + ? + ?)}{4} = ?$
  - Average for the control group: $\frac{(? + 7 + 5 + 6)}{4} = ?$

- Assume that our collected outcomes show that the possible values for the missing data are between 0 and 10
- Let's see how to calculate the bounds for the ATE!
:::
:::
:::

## A simple example

:::{style="margin-top: 30px; font-size: 28px;"}
- To find the [upper bound]{.alert} on the treatment effect estimate, [substitute 10 for the missing values in the treatment
group and 0 for the missing value in the control group]{.alert}

- Upper bound: $\frac{(7 + 10 + 10 + 10)}{4} - \frac{(0 + 7 + 5 + 6)}{4} = \frac{37}{4} - \frac{18}{4} = 4.75$

- To find the lower bound on the treatment effect estimate, [substitute 0 for the missing values in the treatment group and 10 for the missing value in the control group]{.alert}

- Lower bound: $\frac{(7 + 10 + 0 + 0)}{4} - \frac{(10 + 7 + 5 + 6)}{4} = \frac{17}{4} - \frac{28}{4} = -2.75$

- So, the [ATE is between -2.75 and 4.75]{.alert}... and indeed it is ([2]{.alert})! üéâ

- But as you can see, [the bounds are pretty wide]{.alert}... 
:::

## Trimming the bounds with stronger assumptions
### Monotonicity revisited

:::{style="margin-top: 30px; font-size: 30px;"}
- [Lee (2009)](https://academic.oup.com/restud/article/76/3/1071/1590707) suggested that we can [trim the bounds]{.alert} to make them more informative (and narrower)
- The key assumption of Lee is [monotonicity]{.alert}, similar to what we discussed in the context of non-compliance
- Remember our four types of respondents? Always-Reporters, Never-Reporters, If-Treated Reporters, and If-Untreated Reporters
- The assumption is that [there are no If-Untreated reporters]{.alert}, similar to the "no defiers" assumption in non-compliance
- For example, receiving a job-training programme might make someone more likely to respond (and thus more likely to be surveyed about their wages), but [it will not make anyone less likely]{.alert} to respond
:::

## Trimming the bounds with stronger assumptions
### Monotonicity revisited

:::{style="margin-top: 30px; font-size: 24px;"}
- Under monotonicity, [we can bound the average treatment effect for Always-Reporters]{.alert} 
- For them, the ATE is defined as:

$$E[Y_i(1) | R_i(1) = 1, R_i(0) = 1] - E[Y_i(0) | R_i(1) = 1, R_i(0) = 1]$$

- That is, we observe $Y(0)$ only for the Always-Reporters, as If-Treated-Reporters and Never-Reporters produce only missing values, and under monotonicity we assume there are no If-Untreated-Reporters
- The difficult part is to estimate the ATE for Always-Reporters, as [we observe $Y(1)$ for both Always-Reporters and If-Treated-Reporters]{.alert}
- We can estimate the share of Always-Reporters by assuming that the share of Always-Reporters in the control group is the same as in the treatment group
- The difference is the share of If-Treated-Reporters in the treatment group, we can use the lower and upper bound of the distribution of outcomes to estimate the ATE for Always-Reporters
:::

## Trimming the bounds with stronger assumptions

:::{style="margin-top: 30px; font-size: 27px;"}
- We can bound the effect for Always-Reporters by [taking the means of trimmed versions of the treated outcome distribution]{.alert}
- A lower bound comes from trimming off the share of compliers from the top of the distribution, and an upper bound comes from trimming this share from the bottom
- There are several `R` packages that calculate Lee bounds
  - Have a look at <https://github.com/lbassan/attritevis>
- Although this is a good solution to attrition, [it has received some criticism too](https://blogs.worldbank.org/en/impactevaluations/dealing-attrition-field-experiments)
- For instance, [McKenzie (2024)](https://blogs.worldbank.org/en/impactevaluations/lee-bounds-in-practice) argues that it's not clear how to use Lee bounds with binary variables, that incorporating covariates isn't straightforward ([paper proposing a solution here](https://arxiv.org/abs/2309.08985)), and that bounds are not easy to use with clustered data
:::

## How Lee bounds work 

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width=50%}
- [Step 1:]{.alert} Figure out who the always-reporters are
  - If 90% of control group stays and 95% of treatment group stays
  - Then at least 90% must be always-reporters
  - The extra 5% in treatment group are if-treated reporters
- [Step 2:]{.alert} Trim extreme values
  - Remove the same proportion of extreme values from treatment group
  - This accounts for the if-treated reporters
- [Step 3:]{.alert} Calculate the bounds
  - [Lower bound]{.alert}: We remove the 5% with the highest wages in the treatment group
  - [Upper bound]{.alert}: We remove the 5% with the lowest wages in the treatment group
:::

:::{.column width=50%}
- [What if the control group has less attrition?]{.alert}
  - Monotonicity assumes that [there is no if-untreated reporters]{.alert}
  - If the treatment group has better retention, we assume those extra participants are people who were "saved" from dropping out by the treatment 
  - But if the control group has better retention, [we assume the extra participants are people who would have dropped out if they had received the treatment]{.alert}
  - So we trim the control group to match the treatment group
  - [Lower bound:]{.alert} we remove the 5% with the highest wages in the control group
  - [Upper bound:]{.alert} we remove the 5% with the lowest wages in the control group
:::
:::
:::



# Handling attrition in R {background-color="#2d4563"}

## Handling attrition in `R`
### `attritevis` package

:::{style="margin-top: 30px; font-size: 27px;"}
- The `attritevis` package has several useful functions to [visualise the attrition process]{.alert}, [calculate the bounds]{.alert}, and [estimate the ATE]{.alert}
- It has very few assumptions:
  - Data must be ordered by survey questions, i.e., if respondents answered Q1 before Q2, the variable Q1 must appear before Q2 (i.e., in an earlier column) in the dataframe
  - Attrition is defined as completely leaving the survey, not just skipping a question.
  - For balance tests, treatment and control conditions must be defined
- The package is available on GitHub: <https://github.com/lbassan/attritevis>
:::

## An empathy experiment

:::{style="margin-top: 30px; font-size: 22px;"}
:::{.columns}
:::{.column width=50%}
- The experiment manipulates peer-praise and measures empathy in a behavioural task
- There are two arms in the peer-praise randomisation: peer-praise and no praise (control)
- In the first arm, a word cloud of praise, drawn from real praise collected in a pilot study, is given for people who behave empathetically, with a line of text about peer group average thermometer ratings towards people who are empathetic
  - ‚ÄúPeers of yours on this platform have said they hold favourable feelings towards people who engage in empathetic behaviour, with an average of 7.9, on a scale of 0 (least favourable) to 10 (most favourable). That same peer group provided real feedback for empathetic behaviour which is pictured in the word cloud below‚Äù 
:::

:::{.column width=50%}
- Respondents in the control condition do not receive any additional information
 
:::{style="text-align: center; margin-top: -30px;"}
![](figures/wordcloud.png){width=50%}

![](figures/cards.png){width=50%}
:::
:::
:::
:::

## Installing the package and loading a dataset

:::{style="margin-top: 30px; font-size: 26px;"}
- To install and load the package, run the following code:

```{r}
#| echo: true
#| eval: true
# devtools::install_github("lbassan/attritevis", dependencies = TRUE)
library(attritevis)
library(ggrepel)

test_data <- read.csv("./test_data.csv")
names(test_data)
```
:::

## Attrition dataframe

:::{style="margin-top: 30px; font-size: 23px;"}

- The `attrition()` function creates a frame that indicates, per question: 
  - `attrited` -- how many respondents attrited (left the survey) at each question
  - `prop_q` -- number of attrited respondents / number of respondents entering into the question
  - `proportion` -- number of attrited respondents / number of respondents who entered survey  
  - `questions` -- question names
  - `responded` -- how many respondents responded in each question  
  - `prop_r` -- number of respondents who responded / number of respondents who started the survey
- "Skippers" are respondents who did not answer a question but continued with the survey. They are not considered attrited

```{r}
#| echo: true
#| eval: true
attrition_data <- attritevis::attrition(test_data)
head(attrition_data, 20)

sum(attrition_data$attrited) #How many respondents attrited overall?
sum(attrition_data$attrited)/nrow(test_data) #What proportion of the overall sample is this?
```
:::

## Visualising the attrition process

:::{style="margin-top: 30px; font-size: 24px;"}
- The `plot_attrition()` function shows the attrition process

```{r}
#| echo: true
#| eval: true
plot_attrition(test_data)  
```
:::

## Visualising the attrition process

:::{style="margin-top: 30px; font-size: 24px;"}
- We can specify `y="responded"` to account for response, rather than attrition

```{r}
#| echo: true
#| eval: true
plot_attrition(test_data, y="responded")  
```
:::

## Visualising the attrition process

:::{style="margin-top: 30px; font-size: 24px;"}
- With `treatment_q`, we can specify the treatment question, and with `outcome_q`, we can specify the outcome questions

```{r}
#| echo: true
#| eval: true
attritevis::plot_attrition(test_data,
              y = "responded",
              outcome_q = c("cards1", "cards2",  "cards3"),
              treatment_q = "treat1",
              mycolors = c(treatment = "#000066",
                           control = "#CC0033"))
```
:::

## Balance tests

:::{style="margin-top: 30px; font-size: 24px;"}
- The `balance_cov()` function calculates the balance of covariates between the treatment and control groups

```{r}
#| echo: true
#| eval: true
attritevis::balance_cov(data = test_data, 
        treatment = "treat1", 
        question = "age")
```
:::

## Balance tests

:::{style="margin-top: 30px; font-size: 24px;"}
- We can also use the function `balance_cov()` when the covariate (`question`) is a factor, but we must specify which factor we are interested in

```{r}
#| echo: true
#| eval: true
attritevis::balance_cov(data = test_data, 
        treatment = "treat1", 
        question = "sex",
        factor = TRUE,
        factor_name = "female")
```
:::

## Balance across attrition

:::{style="margin-top: 30px; font-size: 24px;"}
- Next, we can check whether our treatment is correlated with attrition at any moment in the survey with the `balance_attrite()` function

```{r}
#| echo: true
#| eval: true
attritevis::balance_attrite(data = test_data, 
        treatment = "treat1", 
        question = "Happy_3_1")
```
:::

## Calculating the bounds

:::{style="margin-top: 30px; font-size: 24px;"}
- Finally, we can estimate both Manski bounds and Lee bounds with the `bounds()` function
- We have to install the [`attrition`](https://alexandercoppock.com/attrition/) package to estimate the bounds

```{r}
#| echo: true
#| eval: true
# devtools::install_github("acoppock/attrition")
attritevis::bounds(data = test_data, 
        treatment = "treat1", 
        DV = "cards1",
        type = "Manski")
```

```{r}
#| echo: true
#| eval: true
attritevis::bounds(data = test_data, 
        treatment = "treat1", 
        DV = "cards1", 
        type = "Lee")
```
:::

## Summary

:::{style="margin-top: 30px; font-size: 27px;"}
- Attrition is a common issue in experiments, and it can bias estimates (as everything else we've seen so far üòÖ)
- We can handle attrition by assuming that it is related to observed variables
- In this case, we can use [inverse probability weighting]{.alert} (IPW) to estimate the ATE
- We can also use [extreme bounds analysis]{.alert} (EBA) to evaluate the sensitivity of the ATE to different assumptions about the missing data
- [Lee bounds]{.alert} are a way to trim the bounds to make them more informative
- The `attritevis` package in `R` has several functions to visualise the attrition process, calculate the bounds, and estimate the ATE
- Consider using these functions in your next experiment! ü§ì
:::

# ...and that's it! üéâ {background-color="#2d4563"}

# See you next time! üòâ {background-color="#2d4563"}